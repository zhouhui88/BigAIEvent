{
  "displayTitle": "2026年2月5日 AI大事件",
  "title": "AI大事件",
  "generatedAt": "2026-02-05 11:41 Asia/Shanghai",
  "window": "最近24–36小时",
  "items": [
    {
      "id": "hn-0-voxtral-transcribe-2",
      "lang": "en",
      "type": "product",
      "hotness": 100,
      "title": "Voxtral Transcribe 2",
      "summary": "Mistral 更新语音转写（speech-to-text）相关能力。 亮点：开源权重（open-weights）、Apache 2.0 许可、支持实时（real-time）、支持说话人分离（diarization）、低延迟（low latency）",
      "sources": [
        {
          "name": "Hacker News",
          "url": "https://news.ycombinator.com/"
        },
        {
          "name": "原文",
          "url": "https://mistral.ai/news/voxtral-transcribe-2"
        }
      ]
    },
    {
      "id": "hn-20-claude-is-a-space-to-think",
      "lang": "en",
      "type": "product",
      "hotness": 78,
      "title": "Claude is a space to think",
      "summary": "Anthropic 发布文章解释 Claude 的产品定位（space to think）。",
      "sources": [
        {
          "name": "Hacker News",
          "url": "https://news.ycombinator.com/"
        },
        {
          "name": "原文",
          "url": "https://www.anthropic.com/news/claude-is-a-space-to-think"
        }
      ]
    },
    {
      "id": "hn-28-a-real-world-benchmark-for-ai-code-revie",
      "lang": "en",
      "type": "product",
      "hotness": 67,
      "title": "A real-world benchmark for AI code review",
      "summary": "基准/评测：提出面向 AI 代码审查（code review）的真实场景评测。",
      "sources": [
        {
          "name": "Hacker News",
          "url": "https://news.ycombinator.com/"
        },
        {
          "name": "原文",
          "url": "https://www.qodo.ai/blog/how-we-built-a-real-world-benchmark-for-ai-code-review/"
        }
      ]
    },
    {
      "id": "hn-4-ai-is-killing-b2b-saas",
      "lang": "en",
      "type": "product",
      "hotness": 65,
      "title": "AI is killing B2B SaaS",
      "summary": "观点文章讨论 AI 对传统 B2B SaaS 的冲击。",
      "sources": [
        {
          "name": "Hacker News",
          "url": "https://news.ycombinator.com/"
        },
        {
          "name": "原文",
          "url": "https://nmn.gl/blog/ai-killing-b2b-saas"
        }
      ]
    },
    {
      "id": "hn-3-claude-code-connect-to-a-local-model-whe",
      "lang": "en",
      "type": "product",
      "hotness": 61,
      "title": "Claude Code: connect to a local model when your quota runs out",
      "summary": "经验帖：Claude Code 额度用尽时，如何切换连接本地开源模型继续工作。 亮点：可切换本地/开源模型",
      "sources": [
        {
          "name": "Hacker News",
          "url": "https://news.ycombinator.com/"
        },
        {
          "name": "原文",
          "url": "https://boxc.net/blog/2026/claude-code-connecting-to-local-models-when-your-quota-runs-out/"
        }
      ]
    },
    {
      "id": "jiqizhixin-1",
      "lang": "zh",
      "type": "product",
      "hotness": 60,
      "title": "史上首次！米兰冬奥基于阿里千问打造奥运官方大模型",
      "summary": "你有没有想过一个问题：为什么和 AI 对话，总觉得少了点「人味儿」。 不是它回答得不够准确，也不是它理解不了你的意思，而是每次交互都很机械。 你问一句，等它答完，然后突然画面一转，对不起，它对现实世界的观察仿佛瞬间「掉线」。那几秒里，AI 仿佛顺手关掉了眼睛和耳朵，陷入一种「间歇性失明失聪」的状态，根本不能根据眼前瞬息万变的画面实时调整自己的反应。 这种感觉，就像两个人在用对讲机聊天。你按住通话键说话时，对方听不见；对方说话时，你也插不上嘴。一次只能一个方向传递信息。 这不是产品设计问题，而是技术限制。因为绝大多数 AI 都在用单工模式运行，用起来感觉很死板。 2 月 4 日，面壁开源了行业首个全双工全模态大模型 MiniCPM-o 4.5，相比已有多模态模型，MiniCPM-o 4.5 首次实现了「边看边听边说」以及「自主交互」的全模态能力，模型不再只是把视觉、语音作为静态输入处理，而是能够在实时、多模态信息流中持续感知环境变化，并在输出的同时保持对外界的理解。 目前，MiniCPM-o 4.5 已在 GitHub、Hugging Face 等平台开源： 开源地址：https://github.com/OpenBMB/MiniCPM-o Hugging Face: https://huggingface.co/openbmb/MiniCPM-o-4_5 虽然参数量只有 9B，MiniCPM-o 4.5 却在全模态、视觉理解、文档解析、语音理解和生成、声音克隆等方面，均做到了全模态模型 SOTA 水平。在涵盖 8 个主流评测基准的 OpenCompass 综合评估中得分 77.6 。 MiniCPM-o 4.5 在 MMBench（综合视觉理解）、MathVista（数学推理）及 OmniDocBench（文档解析）等关键任务上击败了顶级闭源模型 Gemini 2.5 Fl",
      "sources": [
        {
          "name": "机器之心",
          "url": "https://www.jiqizhixin.com/articles/2026-02-05"
        }
      ]
    },
    {
      "id": "jiqizhixin-2",
      "lang": "zh",
      "type": "product",
      "hotness": 60,
      "title": "第二代AI预训练范式：预测下个物理状态",
      "summary": "近日，美团推出全新多模态统一大模型方案 STAR（STacked AutoRegressive Scheme for Unified Multimodal Learning），凭借创新的 \"堆叠自回归架构 + 任务递进训练\" 双核心设计，实现了 \"理解能力不打折、生成能力达顶尖\" 的双重突破。 在 GenEval（文本 - 图像对齐）、DPG-Bench（复杂场景生成）、ImgEdit（图像编辑）等 benchmark 中，STAR 实现了 SOTA 性能；用最简训练逻辑与紧凑模型设计让统一多模态大模型真正走向工业级落地。 论文标题：STAR: Stacked AutoRegressive Scheme for Unified Multimodal Learning 论文链接：https://arxiv.org/pdf/2512.13752 项目主页：https://star-mm-ai.github.io 代码地址：https://github.com/MM-MVR/STAR 关键词：统一多模态、堆叠自回归、任务渐进式训练 一、行业痛点：统一多模态大模型的 “能力诅咒” 在通向 AGI 的进程中，将 “视觉理解” 与 “图像生成” 统一于单一参数空间被视为多模态大模型的圣杯，然而实践层面却长期受制于 “能力诅咒”，具体表现为三重矛盾。 1. 优化目标互斥 —— 语义对齐与像素保真的零和博弈 理解任务的核心是 \"语义对齐与逻辑推理\"—— 比如识别图像中的物体、回答图文相关问题，需要模型精准捕捉跨模态的语义关联；而生成任务的核心是 \"像素保真与创意表达\"—— 比如根据文本描述生成高清图像，需要模型兼顾细节还原与内容连贯性。两者的优化目标、特征空间显著不同，导致联合训练陷入零和博弈：强化生成能力，理解准确率会下降；深耕理解任务，生成图像的清晰度、语义一致性会打折。 2. 训练范",
      "sources": [
        {
          "name": "机器之心",
          "url": "https://www.jiqizhixin.com/articles/2026-02-04-13"
        }
      ]
    },
    {
      "id": "jiqizhixin-3",
      "lang": "zh",
      "type": "product",
      "hotness": 60,
      "title": "产研协同 智启未来：科学智能“百团百项”工程产研共创沙龙在沪顺利举行",
      "summary": "1. 医疗AI的深水区：从通用视觉到超声专业理解 超声成像（Ultrasound）作为全球医疗中应用最广泛的影像手段之一，在妇产科、急诊及心脏病学等场景中具有不可替代的地位。然而，与 CT / MRI 等模态相比，超声影像的自动理解长期面临更高门槛： 操作依赖性强 ：超声影像受操作者手法影响，质量波动大、伪影多 。 空间关系复杂 ：不同于 CT/MRI 的静态切片，超声呈现的是动态的、具有强空间上下文关系的结构 。 评测体系缺失 ：虽然通用视觉大模型（LVLMs）如 GPT-4V、Gemini 表现惊人，其在超声这一高专业度场景下的能力，长期缺乏系统、可复现的评估体系。 在此背景下，U2-BENCH 被提出，作为首个系统性评估LVLMs在超声领域能力的深度基准，涵盖了分类、检测、回归及文本生成四大任务维度。 2. 核心 设计 ：全谱系解剖覆盖与临床启发式任务 U2-BENCH的核心价值在于其高度的临床相关性和严密的构建流程： 2.1 超大规模、多来源的真实临床数据 广度覆盖 ：汇集了来自 40 个授权数据集的 7,241 个案例 ，跨越 15 个解剖区域 （如胎儿、心脏、乳腺、甲状腺等） 。 深度场景 ：涵盖 50 个临床应用场景 ，确保了评估结果能真实反映模型在医疗一线的能力 。 2.2 四级能力分解 ， 八项临床任务 U2-BENCH 将“超声理解”拆解为四个能力层级、八项具体任务： 分类任务 ：疾病诊断（DD）、标准切面识别与质量评估（VRA） 。 检测任务 ：病灶定位（LL）、器官检测（OD）、关键点检测（KD） 。 回归任务 ：临床数值估计（CVE，如射血分数、脂肪肝百分比） 。 生成任务 ：结构化报告生成（RG）、解剖描述生成（CG） 。 3. 实验验证：SOTA 模型的 能力 边界 U2-BENCH上系统评测了 23个 领先 视觉语言模型（包括 GPT-5",
      "sources": [
        {
          "name": "机器之心",
          "url": "https://www.jiqizhixin.com/articles/2026-02-04-11"
        }
      ]
    },
    {
      "id": "jiqizhixin-4",
      "lang": "zh",
      "type": "product",
      "hotness": 60,
      "title": "突破RNA设计瓶颈，上智院联合复旦、上交提出全球首个强化学习与潜扩散融合框架SOLD",
      "summary": "编辑｜张倩 人给 AI 打工的一天，居然这么快就来了。 最近，一个名叫「rentahuman.ai」的网站上线了，它被定位为「AI 的肉身层」。众所周知，AI 没有身体，虽然机器人已经在开发了，但现阶段还不太好用。因此，在一些需要身体的场合，比如取货送货、活动签到、实地勘察、餐厅试吃、参加线下会议，AI 就得找个人替自己跑一趟，这就是网站的设计初衷。 通过 MCP 协议或 REST API，AI 可以像调用工具一样搜索、预订并雇佣人类来完成线下任务 。 支持的智能体类型如下： 据网站开发者 @AlexanderTw33ts 透露，网站上线第一晚就有超过 130 人报名参加，其中还包括人工智能初创公司的创始人和首席执行官。而在上线不到 48 个小时的时间里，可用的人类劳动力就突破了 1 万，现在更是超过了 2 万。当然，这里面可能大部分都是看热闹的。 对于注册成为「跑腿」的人类来说，网站的规则也比较友好，允许人类自己设置时薪，还不需要闲聊。 在网站上，我们可以看到所有可用人力的列表。他们来自世界各地的不同国家，设定的时薪从十几美元到几十美元不等。 点开人物资料卡片，我们可以看到某个人类的具体信息，比如定位、服务半径等。 从网站上，我们还可以看到一些已经发布的任务，比如拍一张人工智能永远看不到的照片、试吃新餐厅、从市中心的美国邮政局领取包裹、检查 API_Keys…… 被雇佣检查 API_Keys 的人类感慨地说：这个时代太诡异了，人类居然成了智能体的副驾。 当然，也有一些比较抽象的任务，比如举牌子，牌子上写着「AI 付钱让我举这个牌子」。 这个网站让我们再次看到了 MCP 的价值。 但是，该网站的出现也引发了一些疑问，比如智能体要怎么付钱？目前发布任务的到底是智能体还是背后的人类金主？这是不是继 Moltbook 之后的另一场炒作？ 还有个问题更有意思：AI 要怎么确认人类保",
      "sources": [
        {
          "name": "机器之心",
          "url": "https://www.jiqizhixin.com/articles/2026-02-04-9"
        }
      ]
    },
    {
      "id": "jiqizhixin-5",
      "lang": "zh",
      "type": "product",
      "hotness": 60,
      "title": "从斑马鱼到机器鱼：机器人实验重塑神经行为研究",
      "summary": "IEEE/CVF 计算机视觉与模式识别会议 CVPR 2026 将于 2026年6月3日–6月7日 在美国科罗拉多州丹佛举办。我们将在 CVPR 期间举办 第六届对抗机器学习计算机视觉研讨会（6th AdvML@CV），Workshop 预计安排在 6月3日或6月4日。 本届主题聚焦：Safety of Vision-Language Agents（视觉-语言智能体安全）。 主题聚焦：视觉-语言智能体的安全与鲁棒性 多模态基础模型推动了视觉理解、生成与推理能力的跃迁，也让 Vision-Language Agents（视觉-语言智能体） 迅速成为“感知—语言推理—行动规划”一体化的新范式。 但随着智能体自主性增强，攻击面也从传统像素级扰动扩展到更复杂的安全风险：例如 对抗提示（adversarial prompts）、指令注入（instruction injection）、jailbreak 操控 等，它们可能扰乱推理链条、误导感知决策，甚至诱发危险行为。 我们希望通过本次 Workshop，汇聚计算机视觉、多模态学习与 AI Safety 社区的研究者与工程实践者，共同推进安全、鲁棒、可信的视觉-语言智能体研究与落地。 论文征稿 本次研讨会诚邀与以下主题相关（但不限于）的投稿： •Attack and defense on vision-language agents •Datasets and benchmarks that could evaluate vision-language agents •Adversarial / Jailbreak attacks on vision-language agents •Improving the robustness of agents or deep learning systems •Interpreting and",
      "sources": [
        {
          "name": "机器之心",
          "url": "https://www.jiqizhixin.com/articles/2026-02-04-7"
        }
      ]
    }
  ]
}
